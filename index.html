<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-dark.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <title>Wells Fargo Analytics by PeterABruno</title>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1>Wells Fargo Analytics</h1>
          <h2>Analysis of social media content</h2>
        </header>

        <section id="downloads" class="clearfix">
          <a href="https://github.com/PeterABruno/WellsFargoAnalytics/zipball/master" id="download-zip" class="button"><span>Download .zip</span></a>
          <a href="https://github.com/PeterABruno/WellsFargoAnalytics/tarball/master" id="download-tar-gz" class="button"><span>Download .tar.gz</span></a>
          <a href="https://github.com/PeterABruno/WellsFargoAnalytics" id="view-on-github" class="button"><span>View on GitHub</span></a>
        </section>

        <hr>

        <section id="main_content">
          <h3>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h3>

<p>Wells Fargo provided us with a dataset containing social media posts from Twitter and Facebook. Our team was tasked with cleaning, and analyzing the data, then providing business insights based on the results. My teammates Alex and Kaya were the coders, while Zach and I analyzed and delivered the insights. With our team divided into two roles, communication between the coders and analysts were vital so the data they were mining for was coordinated with what business aspects we wanted to examine.
<img alt=""></p>

<h3>
<a id="methodology" class="anchor" href="#methodology" aria-hidden="true"><span class="octicon octicon-link"></span></a>Methodology</h3>

<p>We took the dataset which was given to us, then created a smaller data frame and analyze those posts making inferences about the larger population. From this smaller data frame we cleaned the data to extract the nonsensical words which would be of zero value to us in our analysis. All this code is under “Part A” under the Code portion.</p>

<h4>
<a id="uncleaned-data" class="anchor" href="#uncleaned-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Uncleaned data:</h4>

<p><img src="http://i.imgur.com/hDTQPM9.png" alt=""></p>

<h4>
<a id="cleaned-data" class="anchor" href="#cleaned-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cleaned data:</h4>

<p><img src="http://i.imgur.com/vSTViUx.png" alt="">
From this, we used lists of positive and negative words and matched those words to text in the social media posts. A sentiment score for each post was calculated by the number of positive words minus the negative words. Very positive and very negative posts were defined as the score being &gt;= 2 or &lt;= 2 respectively. This data frame was further divided this into data frames for posts mentioning each bank respectively. Also, we made a data frame for posts containing "name". Finally, we ran the sentiment analysis on these subsets and calculated their scores and made graphs.
Additionally, from the sample database, we created 10 word clouds, one "very positive" and one "very negative" for each bank and then the same thing for all four banks combined, demonstrating what conversations were taking in regards to the banks. </p>

<p>POSTS → 1000 Post DF → Smaller DFs of Posts → Sentiment Analysis</p>

<p><img src="http://i.imgur.com/GD93wxf.png" alt=""></p>

<h3>
<a id="data" class="anchor" href="#data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data</h3>

<p>Part A: Cleaning of the Data
``` R df = read.table('dataset.txt',sep="|",header=T)
df$FullText = as.character(df$FullText)</p>

<h5>
<a id="remove-non-ascii-characters" class="anchor" href="#remove-non-ascii-characters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Remove non-ascii characters</h5>

<p>df.texts.clean = as.data.frame(iconv(df$FullText, "latin1", "ASCII", sub=""))
colnames(df.texts.clean) = 'FullText'</p>

<p>df$FullText = df.texts.clean$FullText</p>

<h5>
<a id="test-10000-texts-good-sample-size" class="anchor" href="#test-10000-texts-good-sample-size" aria-hidden="true"><span class="octicon octicon-link"></span></a>test 10,000 texts: good sample size</h5>

<p>idx.10000 = sample(1:nrow(df),10000)
df.10000 = df[idx.10000,]</p>

<p>df.entire = df
df = df.10000</p>

<h5>
<a id="load-using-the-tm-library" class="anchor" href="#load-using-the-tm-library" aria-hidden="true"><span class="octicon octicon-link"></span></a>Load using the tm library</h5>

<p>library(tm) 
docs &lt;- Corpus(DataframeSource(as.data.frame(df[,6])))   </p>

<h5>
<a id="remember-it-matters-the-order-in-which-tm_map-expressions-are-run" class="anchor" href="#remember-it-matters-the-order-in-which-tm_map-expressions-are-run" aria-hidden="true"><span class="octicon octicon-link"></span></a>REMEMBER: IT MATTERS THE ORDER IN WHICH TM_MAP EXPRESSIONS ARE RUN</h5>

<p>library(rJava)
docs &lt;- tm_map(docs, content_transformer(tolower)) # convert to lowercase first
docs &lt;- tm_map(docs, removeWords, stopwords('english'))
docs &lt;- tm_map(docs, removeWords, stopwords(kind = "SMART"))</p>

<h5>
<a id="metadatarecurrent-words" class="anchor" href="#metadatarecurrent-words" aria-hidden="true"><span class="octicon octicon-link"></span></a>metaData/recurrent words</h5>

<p>myMeta &lt;- c("name","bank","banka","bankb","bankc", "bankd", "banke",
            "internet","https", "rettwit", "twithndl", "twit_hndl_banka",
            "twit_hndl_bankb","twit_hndl_bankc","twit_hndl_bankd", "phone",
            "dirmsg", "street","name_resp","bankds", "and", "for", "the", "you",
            "twithndlbanka","dir_msg","ret_twit","twit_hndl")
docs &lt;- tm_map(docs, removeWords, myMeta)
docs &lt;- tm_map(docs, stripWhitespace)
docs &lt;- tm_map(docs, removePunctuation)
docs &lt;- tm_map(docs, PlainTextDocument)</p>

<p>dtm &lt;- DocumentTermMatrix(bankA.docs)
dtm = removeSparseTerms(dtm, 0.98)</p>

<h5>
<a id="creates-new-data-frame-out-of-cleanedprocessed-text" class="anchor" href="#creates-new-data-frame-out-of-cleanedprocessed-text" aria-hidden="true"><span class="octicon octicon-link"></span></a>creates new data frame out of cleaned/processed text</h5>

<p>new.df &lt;-data.frame(text=unlist(sapply(dtm, <code>[</code>, "content")), stringsAsFactors=F)</p>

<h5>
<a id="this-ends-preprocessing" class="anchor" href="#this-ends-preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>THIS ENDS PREPROCESSING</h5>

<p>bankA.idx = which(sapply(df$FullText,function(x) grepl("BankA",x)))
bankB.idx = which(sapply(df$FullText,function(x) grepl("BankB",x)))
bankC.idx = which(sapply(df$FullText,function(x) grepl("BankC",x)))
bankD.idx = which(sapply(df$FullText,function(x) grepl("BankD",x)))</p>

<p>df$BankID = vector(mode="numeric",length = nrow(df))
df$BankID[bankA.idx] = "BankA"
df$BankID[bankB.idx] = "BankB"
df$BankID[bankC.idx] = "BankC"
df$BankID[bankD.idx] = "BankD"</p>

<p>bankA.docs = docs[bankA.idx]
bankB.docs = docs[bankB.idx]
bankC.docs = docs[bankC.idx]
bankD.docs = docs[bankD.idx] </p>

<p>dtm &lt;- DocumentTermMatrix(bankA.docs)
dtm = removeSparseTerms(dtm, 0.98)</p>

<h6>
<a id="creates-new-data-frame-out-of-cleanedprocessed-text-1" class="anchor" href="#creates-new-data-frame-out-of-cleanedprocessed-text-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>creates new data frame out of cleaned/processed text</h6>

<p>new.df &lt;-data.frame(text=unlist(sapply(dtm, <code>[</code>, "content")), stringsAsFactors=F) #Posts that have been cleaned</p>

<p>findFreqTerms(dtm,300)</p>

<p>freq &lt;- colSums(as.matrix(dtm))<br>
freq
ord &lt;- order(freq)   </p>

<p>library(wordcloud)
wordcloud(names(freq), freq, colors=brewer.pal(8, "Dark2"))</p>

<p>Sentiment Analysis Code</p>

<div class="highlight highlight-source-r"><pre><span class="pl-c">##### Since we can't find a great package in R, I'm going to use an</span>
<span class="pl-c">##### example I found online to build our own</span>
<span class="pl-c">##### Based on: http://www.ihub.co.ke/blogs/23216</span>

<span class="pl-c">##### Only need to do once</span>
<span class="pl-c">##### Download and upload: http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar</span>
<span class="pl-c">#####system('unrar e opinion-lexicon-English.rar')</span>

<span class="pl-smi">pos</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>positive-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)
<span class="pl-smi">neg</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>negative-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)

<span class="pl-v">score.sentiment</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">sentences</span>, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>none<span class="pl-pds">'</span></span>)
{
  require(<span class="pl-smi">plyr</span>)
  require(<span class="pl-smi">stringr</span>)

<span class="pl-c">##### we got a vector of sentences. plyr will handle a list</span>
<span class="pl-c">##### or a vector as an "l" for us</span>
<span class="pl-c">##### we want a simple array ("a") of scores back, so we use "l" + "a" + "ply" = "laply":</span>
  <span class="pl-v">scores</span> <span class="pl-k">=</span> laply(<span class="pl-smi">sentences</span>, <span class="pl-k">function</span>(<span class="pl-smi">sentence</span>, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>) {

<span class="pl-c">##### clean up sentences with R's regex-driven global substitute, gsub():</span>
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span>[[:punct:]]<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span>[[:cntrl:]]<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\\</span>d+<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
<span class="pl-c">##### and convert to lower case:</span>
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> tolower(<span class="pl-smi">sentence</span>)

<span class="pl-c">##### split into words. str_split is in the stringr package</span>
    <span class="pl-v">word.list</span> <span class="pl-k">=</span> str_split(<span class="pl-smi">sentence</span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\\</span>s+<span class="pl-pds">'</span></span>)
    <span class="pl-c"># sometimes a list() is one level of hierarchy too much</span>
    <span class="pl-v">words</span> <span class="pl-k">=</span> unlist(<span class="pl-smi">word.list</span>)

<span class="pl-c">##### compare our words to the dictionaries of positive &amp; negative terms</span>
    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">pos.words</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">neg.words</span>)

<span class="pl-c">##### match() returns the position of the matched term or NA</span>
<span class="pl-c">##### we just want a TRUE/FALSE:</span>
    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">pos.matches</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">neg.matches</span>)

<span class="pl-c">##### and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():</span>
    <span class="pl-v">score</span> <span class="pl-k">=</span> sum(<span class="pl-smi">pos.matches</span>) <span class="pl-k">-</span> sum(<span class="pl-smi">neg.matches</span>)

    <span class="pl-k">return</span>(<span class="pl-smi">score</span>)
  }, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span>.<span class="pl-smi">progress</span> )

  <span class="pl-v">scores.df</span> <span class="pl-k">=</span> <span class="pl-k">data.frame</span>(<span class="pl-v">score</span><span class="pl-k">=</span><span class="pl-smi">scores</span>, <span class="pl-v">text</span><span class="pl-k">=</span><span class="pl-smi">sentences</span>)
  <span class="pl-k">return</span>(<span class="pl-smi">scores.df</span>)
}

<span class="pl-c">#####breaks data frame into manageable size</span>
<span class="pl-smi">df.1000</span><span class="pl-k">$</span><span class="pl-v">FullText</span> <span class="pl-k">=</span> as.character(<span class="pl-smi">df.1000</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>)

<span class="pl-c">#####subsets data frame into posts that mention Bank A, “name”, etc</span>
<span class="pl-v">df.bankA</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">bankA.idx</span>,]
<span class="pl-v">df.bankB</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">bankB.idx</span>,]
<span class="pl-v">df.bankC</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">bankC.idx</span>,]
<span class="pl-v">df.bankD</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">bankD.idx</span>,]
<span class="pl-v">df.names</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">name.idx</span>,]
<span class="pl-v">df.internet</span> <span class="pl-k">=</span> <span class="pl-smi">df.1000</span>[<span class="pl-smi">internet.idx</span>,]

<span class="pl-c">#####sets the data frame whose scores we will calculate</span>
<span class="pl-v">df.sent</span> <span class="pl-k">=</span> <span class="pl-smi">df.names</span>

<span class="pl-v">scores</span> <span class="pl-k">=</span> score.sentiment(<span class="pl-smi">df.sent</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>, <span class="pl-smi">pos</span>, <span class="pl-smi">neg</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>text<span class="pl-pds">'</span></span>)
<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">very.pos</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span> <span class="pl-k">&gt;</span><span class="pl-k">=</span> <span class="pl-c1">2</span>)
<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">very.neg</span> <span class="pl-k">=</span> as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span> <span class="pl-k">&lt;</span><span class="pl-k">=</span> <span class="pl-k">-</span><span class="pl-c1">2</span>)

<span class="pl-c">##### how many very positives and very negatives</span>
<span class="pl-v">numpos</span> <span class="pl-k">=</span> sum(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">very.pos</span>)
<span class="pl-v">numneg</span> <span class="pl-k">=</span> sum(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">very.neg</span>)

<span class="pl-c">##### global score</span>
<span class="pl-v">global_score</span> <span class="pl-k">=</span> round( <span class="pl-c1">100</span> <span class="pl-k">*</span> <span class="pl-smi">numpos</span> <span class="pl-k">/</span> (<span class="pl-smi">numpos</span> <span class="pl-k">+</span> <span class="pl-smi">numneg</span>) )

<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">mediatype</span> <span class="pl-k">=</span> <span class="pl-smi">df.sent</span><span class="pl-k">$</span><span class="pl-smi">MediaType</span>

<span class="pl-c">##### colors</span>
<span class="pl-v">cols</span> <span class="pl-k">=</span> c(<span class="pl-s"><span class="pl-pds">"</span>#7CAE00<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>#00BFC4<span class="pl-pds">"</span></span>)
names(<span class="pl-smi">cols</span>) <span class="pl-k">=</span> c(<span class="pl-s"><span class="pl-pds">"</span>twitter<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>facebook<span class="pl-pds">"</span></span>)</pre></div>

<div class="highlight highlight-source-r"><pre><span class="pl-c">##### boxplot</span>
library(<span class="pl-smi">ggplot2</span>)
ggplot(<span class="pl-smi">scores</span>, aes(<span class="pl-v">x</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>, <span class="pl-v">y</span><span class="pl-k">=</span><span class="pl-smi">score</span>, <span class="pl-v">group</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>)) <span class="pl-k">+</span>
  geom_boxplot(aes(<span class="pl-v">fill</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>)) <span class="pl-k">+</span>
  scale_fill_manual(<span class="pl-v">values</span><span class="pl-k">=</span><span class="pl-smi">cols</span>) <span class="pl-k">+</span>
  geom_jitter(<span class="pl-v">colour</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>gray40<span class="pl-pds">"</span></span>,<span class="pl-v">position</span><span class="pl-k">=</span>position_jitter(<span class="pl-v">width</span><span class="pl-k">=</span><span class="pl-c1">0.2</span>), <span class="pl-v">alpha</span><span class="pl-k">=</span><span class="pl-c1">0.3</span>) <span class="pl-k">+</span>
  labs(<span class="pl-v">title</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Media Type's Sentiment Scores: Text including 'name'<span class="pl-pds">"</span></span>) <span class="pl-k">+</span> 
  xlab(<span class="pl-s"><span class="pl-pds">'</span>Media Type<span class="pl-pds">'</span></span>) <span class="pl-k">+</span> ylab(<span class="pl-s"><span class="pl-pds">'</span>Sentiment Score<span class="pl-pds">'</span></span>)

<span class="pl-c">##### barplot of average score</span>
<span class="pl-v">meanscore</span> <span class="pl-k">=</span> tapply(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span>, <span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">mediatype</span>, <span class="pl-smi">mean</span>)
<span class="pl-v">df.plot</span> <span class="pl-k">=</span> <span class="pl-k">data.frame</span>(<span class="pl-v">mediatype</span><span class="pl-k">=</span>names(<span class="pl-smi">meanscore</span>), <span class="pl-v">meanscore</span><span class="pl-k">=</span><span class="pl-smi">meanscore</span>)
<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">mediatypes</span> <span class="pl-k">&lt;-</span> reorder(<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">mediatype</span>, <span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">meanscore</span>)

ggplot(<span class="pl-smi">df.plot</span>, aes(<span class="pl-v">x</span> <span class="pl-k">=</span> <span class="pl-k">factor</span>(<span class="pl-smi">mediatypes</span>), <span class="pl-v">y</span> <span class="pl-k">=</span> <span class="pl-smi">meanscore</span>, <span class="pl-v">fill</span><span class="pl-k">=</span><span class="pl-smi">mediatypes</span>)) <span class="pl-k">+</span>
  geom_bar(<span class="pl-v">stat</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>identity<span class="pl-pds">"</span></span>) <span class="pl-k">+</span>
  scale_fill_manual(<span class="pl-v">values</span><span class="pl-k">=</span><span class="pl-smi">cols</span>[order(<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">meanscore</span>)]) <span class="pl-k">+</span>
  labs(<span class="pl-v">title</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Average Sentiment Score: Text including 'name'<span class="pl-pds">"</span></span>) <span class="pl-k">+</span> 
  xlab(<span class="pl-s"><span class="pl-pds">'</span>Media Type<span class="pl-pds">'</span></span>) <span class="pl-k">+</span> ylab(<span class="pl-s"><span class="pl-pds">'</span>Average Score<span class="pl-pds">'</span></span>)

<span class="pl-c">##### barplot of average very positive</span>
<span class="pl-v">mediatype_pos</span> <span class="pl-k">=</span> ddply(<span class="pl-smi">scores</span>, .(<span class="pl-smi">mediatype</span>), <span class="pl-smi">summarise</span>, <span class="pl-v">mean_pos</span><span class="pl-k">=</span>mean(<span class="pl-smi">very.pos</span>))
<span class="pl-smi">mediatype_pos</span><span class="pl-k">$</span><span class="pl-smi">mediatypes</span> <span class="pl-k">&lt;-</span> reorder(<span class="pl-smi">mediatype_pos</span><span class="pl-k">$</span><span class="pl-smi">mediatype</span>, <span class="pl-smi">mediatype_pos</span><span class="pl-k">$</span><span class="pl-smi">mean_pos</span>)

ggplot(<span class="pl-smi">mediatype_pos</span>, aes(<span class="pl-v">x</span> <span class="pl-k">=</span> <span class="pl-k">factor</span>(<span class="pl-smi">mediatype</span>), <span class="pl-v">y</span> <span class="pl-k">=</span> <span class="pl-smi">mean_pos</span>, <span class="pl-v">fill</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>)) <span class="pl-k">+</span>
  geom_bar(<span class="pl-v">stat</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>identity<span class="pl-pds">"</span></span>) <span class="pl-k">+</span>
  scale_fill_manual(<span class="pl-v">values</span><span class="pl-k">=</span><span class="pl-smi">cols</span>[order(<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">meanscore</span>)]) <span class="pl-k">+</span>
  labs(<span class="pl-v">title</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Average Very Positive Sentiment Score: Text including 'name'<span class="pl-pds">"</span></span>) <span class="pl-k">+</span> 
  xlab(<span class="pl-s"><span class="pl-pds">'</span>Media Type<span class="pl-pds">'</span></span>) <span class="pl-k">+</span> ylab(<span class="pl-s"><span class="pl-pds">'</span>Average Score<span class="pl-pds">'</span></span>)

<span class="pl-v">mediatype_neg</span> <span class="pl-k">=</span> ddply(<span class="pl-smi">scores</span>, .(<span class="pl-smi">mediatype</span>), <span class="pl-smi">summarise</span>, <span class="pl-v">mean_neg</span><span class="pl-k">=</span>mean(<span class="pl-smi">very.neg</span>))
<span class="pl-smi">mediatype_neg</span><span class="pl-k">$</span><span class="pl-smi">mediatypes</span> <span class="pl-k">&lt;-</span> reorder(<span class="pl-smi">mediatype_neg</span><span class="pl-k">$</span><span class="pl-smi">mediatype</span>, <span class="pl-smi">mediatype_neg</span><span class="pl-k">$</span><span class="pl-smi">mean_neg</span>)

ggplot(<span class="pl-smi">mediatype_neg</span>, aes(<span class="pl-v">x</span> <span class="pl-k">=</span> <span class="pl-k">factor</span>(<span class="pl-smi">mediatype</span>), <span class="pl-v">y</span> <span class="pl-k">=</span> <span class="pl-smi">mean_neg</span>, <span class="pl-v">fill</span><span class="pl-k">=</span><span class="pl-smi">mediatype</span>)) <span class="pl-k">+</span>
  geom_bar(<span class="pl-v">stat</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>identity<span class="pl-pds">"</span></span>) <span class="pl-k">+</span>
  scale_fill_manual(<span class="pl-v">values</span><span class="pl-k">=</span><span class="pl-smi">cols</span>[order(<span class="pl-smi">df.plot</span><span class="pl-k">$</span><span class="pl-smi">meanscore</span>)]) <span class="pl-k">+</span>
  labs(<span class="pl-v">title</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>Average Very Negative Sentiment Score: Text including 'name'<span class="pl-pds">"</span></span>) <span class="pl-k">+</span> 
  xlab(<span class="pl-s"><span class="pl-pds">'</span>Media Type<span class="pl-pds">'</span></span>) <span class="pl-k">+</span> ylab(<span class="pl-s"><span class="pl-pds">'</span>Average Score<span class="pl-pds">'</span></span>)</pre></div>

<h1></h1>

<h5>
<a id="new" class="anchor" href="#new" aria-hidden="true"><span class="octicon octicon-link"></span></a>NEW</h5>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">new.df.bankA</span> <span class="pl-k">&lt;-</span><span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">bankA.docs</span>, `[[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)
<span class="pl-smi">new.df.bankB</span> <span class="pl-k">&lt;-</span><span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">bankB.docs</span>, `[[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)
<span class="pl-smi">new.df.bankC</span> <span class="pl-k">&lt;-</span><span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">bankC.docs</span>, `[[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)
<span class="pl-smi">new.df.bankD</span> <span class="pl-k">&lt;-</span><span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">bankD.docs</span>, `[[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)
<span class="pl-smi">new.df.name</span> <span class="pl-k">&lt;-</span><span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">name.docs</span>, `[[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)
<span class="pl-smi">new.df.internet</span> <span class="pl-k">&lt;-</span><span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">internet.docs</span>, `[[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)



<span class="pl-v">df.sent</span> <span class="pl-k">=</span> <span class="pl-smi">new.df.bankA</span>

<span class="pl-v">scores</span> <span class="pl-k">=</span> score.sentiment(<span class="pl-smi">df.sent</span><span class="pl-k">$</span><span class="pl-smi">text</span>, <span class="pl-smi">pos</span>, <span class="pl-smi">neg</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>text<span class="pl-pds">'</span></span>)

library(<span class="pl-smi">tm</span>)
library(<span class="pl-smi">wordcloud</span>)

<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-v">text</span> <span class="pl-k">=</span> as.character(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">text</span>)

<span class="pl-v">posIndices</span> <span class="pl-k">=</span> which(as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span>) <span class="pl-k">&gt;</span> <span class="pl-c1">1</span>)
<span class="pl-v">negIndices</span> <span class="pl-k">=</span> which(as.numeric(<span class="pl-smi">scores</span><span class="pl-k">$</span><span class="pl-smi">score</span>) <span class="pl-k">&lt;</span> <span class="pl-k">-</span><span class="pl-c1">1</span>)

<span class="pl-v">posPosts</span> <span class="pl-k">=</span> <span class="pl-smi">scores</span>[<span class="pl-smi">posIndices</span>,<span class="pl-c1">2</span>]
<span class="pl-v">negPosts</span> <span class="pl-k">=</span> <span class="pl-smi">scores</span>[<span class="pl-smi">negIndices</span>,<span class="pl-c1">2</span>]

wordcloud(<span class="pl-smi">posPosts</span>, <span class="pl-v">min.freq</span> <span class="pl-k">=</span> <span class="pl-c1">5</span>, <span class="pl-v">colors</span><span class="pl-k">=</span>brewer.pal(<span class="pl-c1">8</span>, <span class="pl-s"><span class="pl-pds">"</span>Dark2<span class="pl-pds">"</span></span>))


<span class="pl-smi">Global</span> <span class="pl-smi">sentiment</span> scores  (<span class="pl-v">global_score</span> <span class="pl-k">=</span> round( <span class="pl-c1">100</span> <span class="pl-k">*</span> <span class="pl-smi">numpos</span> <span class="pl-k">/</span> (<span class="pl-smi">numpos</span> <span class="pl-k">+</span> <span class="pl-smi">numneg</span>) )

<span class="pl-smi">All</span> Banks (<span class="pl-smi">df.1000</span>)<span class="pl-k">:</span> <span class="pl-c1">59</span>
<span class="pl-smi">Bank</span> <span class="pl-smi">A</span><span class="pl-k">:</span> <span class="pl-c1">57</span>
<span class="pl-smi">Bank</span> <span class="pl-smi">B</span><span class="pl-k">:</span> <span class="pl-c1">56</span>
<span class="pl-smi">Bank</span> <span class="pl-smi">C</span><span class="pl-k">:</span> <span class="pl-c1">74</span>
<span class="pl-smi">Bank</span> <span class="pl-smi">D</span><span class="pl-k">:</span> <span class="pl-c1">50</span>
<span class="pl-smi">Text</span> <span class="pl-smi">with</span> “<span class="pl-smi">NAME</span>”<span class="pl-k">:</span> <span class="pl-c1">50</span>
<span class="pl-smi">Text</span> <span class="pl-smi">with</span> “<span class="pl-smi">INTERNET</span>”<span class="pl-k">:</span> <span class="pl-c1">55</span> </pre></div>

<h3>
<a id="analysis" class="anchor" href="#analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analysis</h3>

<p>The word clusters below are a combination of all the words about a given bank. The next group of clusters are grouped into positive and negative clusters so we have more context to analyze them in and can draw more conclusions.</p>

<h4>
<a id="bank-a" class="anchor" href="#bank-a" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bank A</h4>

<p><img src="http://i.imgur.com/LFu549B.png" alt=""></p>

<h4>
<a id="bank-b" class="anchor" href="#bank-b" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bank B</h4>

<p><img src="http://i.imgur.com/D9Z00Ay.png" alt=""></p>

<h4>
<a id="bank-c" class="anchor" href="#bank-c" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bank C</h4>

<p><img src="http://i.imgur.com/Z2HFK5N.png" alt=""></p>

<h4>
<a id="bank-d" class="anchor" href="#bank-d" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bank D</h4>

<p><a href="http://i.imgur.com/xc9FNhD.png">http://i.imgur.com/xc9FNhD.png</a></p>

<h4>
<a id="all-banks" class="anchor" href="#all-banks" aria-hidden="true"><span class="octicon octicon-link"></span></a>All Banks</h4>

<p><img src="http://i.imgur.com/ULvKtEk.png" alt=""></p>

<p>All the word clusters above are created from the sample data frame we created and for a word to appear, it had to have been used at least 50 times. As one would assume, each bank had topics that were specific to it, but there were some overarching themes for all four banks. The most prevalent words were “call” and phone” which appeared in all the banks’ word cluster with the exception being Bank D. The appearance of “call” and “phone” can be linked to the importance of customer service, especially with the banks’ call centers. With the increasing number of people utilizing the remote call centers, it is increasingly important for those people in the centers to be properly trained and held to the highest standard for their customer service. Banks should consider expanding their budgets for training those individuals to ensure the best customer experience and retain current clientele.
As for the financial topics being discussed via social media, Bank D’s data was the most helpful providing areas such as “financial management”, “grants”, “advisers” while the remaining banks had more broad terms such as “credit card”. This may due to a policy Bank D has where they encourage their customers to leave specific comments so when doing analysis like this, it is easier to have more solid takeaways.</p>

<p>The bank that stood out as being different in the word clusters was Bank D. While all other banks shared words “like” and “can,” Bank D showed more active words such as “swing,” “apply,” and “program.” Bank D may be more effective on a basic customer service level, therefore prompting tweets only when more complex issues come about.</p>

<h4>
<a id="positive-and-negative-word-clusters" class="anchor" href="#positive-and-negative-word-clusters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Positive and Negative Word Clusters</h4>

<p>Bank A
<img src="http://i.imgur.com/5yxwLGH.png" alt="">
There are very few constructive positive takeaways we can have with Bank A’s positive sentiment word cluster. Although there are are words such as “personal”, “service”, “nice”, and “free” which all suggest a positive experience, the negative sentiment word cluster seems to carry more weight with words such as “customer”, “service”, “fraud”, “fucking”, “time”, and “dont”. Other negative words include “worst”, “scam”, and “lost” all which lead me to believe that the customers at Bank A believe their bank to be incompetent and have trust issues.</p>

<p>Bank B
<img src="http://i.imgur.com/d5Gp5hv.png" alt="">
Bank B is very similar to Bank A in the respect that there seems to be trust issues, especially relating to security, with the customers and the bank. In the negative word cloud there are words like “card”, “scam”, “settlement”, “lose” which suggests that there is a lapse in the protocol relating to security for Bank B and possibly their banking cards. On the positive side, customer service seems to be a strong suit for Bank B as one of their most prominent positive words is “support”, “time”, and “team” leading me to believe that Bank B works very efficiently and succinctly in providing the necessary customer service.</p>

<p>Bank C
<img src="http://i.imgur.com/HSNiDW0.png" alt="">
It appears that Bank C’s customers really enjoy whatever “free” services they offer, as well as overwhelming “support”. These positive reports are countered by people running into issues with their “card”, “account”, and “fraud”. Bank C’s problem lies not with their average worker, but with broader institutional framework that allows their customers’ accounts to be compromised.</p>

<p>Bank D
<img src="http://i.imgur.com/rfUCPCl.png" alt="">
Bank D appears to be having some fundamental issues with aspects of banking like “money”, “card”, and “fraud”, but their customer service doesn’t seem to be an issue.</p>

<p>All Banks
Positive Word Cloud
<img src="http://i.imgur.com/Q26IkaB.png" alt="">
Negative Word Cloud
<img src="http://i.imgur.com/8V93D77.png" alt="">
With words relating to time appearing in the positive word cloud like “day” and “today”, one can infer that all the banks are very timely in the services they provide, whether they are customer services or financial. However, looking at the negative word cloud, customers do not seem pleased with the quality of service provided with words such as “money”, “customer”, “service”, “account”, and “card” appearing.</p>

<h4>
<a id="sentiment-analysis" class="anchor" href="#sentiment-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sentiment Analysis</h4>

<p>The following table displays the sentiment analysis scores for all the banks on both Twitter and Facebook. In all the sentiment scores except for Bank B and C's average, Facebook and Twitter's signs were always the same indicating consistent reviews on the platforms but to varying degrees. If you look at All Banks' score for each sentiment score, Facebook's is nearly double that of Twitter demonstrating that people are more opinionated on Facebook than Twitter which makes sense because there is a character limit on Twitter so people can not go on rants like they could on Facebook. Although this is might be extreme, what companies can do to deal with this is to take the time to respond to the customers' posts either reinforcing the positive posts or attempting to amend the customer's issues.
<img src="http://i.imgur.com/IfCf1q5.png" alt=""></p>
        </section>

        <footer>
          Wells Fargo Analytics is maintained by <a href="https://github.com/PeterABruno">PeterABruno</a><br>
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>. Tactile theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.
        </footer>

        
      </div>
    </div>
  </body>
</html>
